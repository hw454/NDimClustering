---
title: Testing Clustering methods.
author: Hayley Wragg
date: "21st Nov 2023"
output: md_document
editor_options: 
  markdown: 
    wrap: sentence
---

# Description

The clustering program takes in GWAS data.
This includes a matrix $\beta$ which contains the strength of association with a trait.
The trait forms the column and the snp is the row.
There's also a matrix of $p$-values these represented the probability that the observed association is due to chance.
There's also the $SE$ matrix with the standard error association with the association scores for each snp, trait pair.

The snp's are chosen based on those with the strongest association to the exposure.

The algorithm attempts to use the association with different traits to identify separate pathways within the data.
We expect the pathways to appear as lines in the original data-space, in order to identify clusters we use two methods to reformat the data.
The first is transforming into the space given by the angles to the axes, this should take lines through the origin with different gradients to balls of data.
The second is principal component analysis, which identifies to the strongest trends within the data.
In this testing process we will look at different combinations of these.

For the test cases I have created synthetics which intentionally has pathways in.

| Test No.    | No. of pathways | PCA method | Angles used (Y or N) | Weight cluster contribution with p-values. | Clustering method | Centroid assignment    |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| [1](#test1) | 2               | none       | N                    | N                                          | standard k-means  | random                 |
| [2](#test2) | **4**           | none       | N                    | N                                          | standard k-means  | random                 |
| [3](#test3) | 2               | none       | **Y**                | N                                          | standard k-means  | random                 |
| [4](#test4) | **4**           | none       | Y                    | N                                          | standard k-means  | random                 |
| [5](#test5) | 4               | none       | N                    | N                                          | standard k-means  | **random from points** |
| [6](#test6) | 4               | none       | Y                    | N                                          | standard k-means  | **random from points** |
| [7](#test7) | 4               | **prcomp** | N                    | N                                          | standard k-means  | random from points     |
| [8](#test8) | 4               | prcomp     | **Y**                | N                                          | standard k-means  | random from points     |
| [9](#test9) | 4               | prcomp     | Y                    | **Y**                                      | standard k-means  | random from points     |

# Instructions for using the package.

## Install package

Load the "ndimclusteringR" package

```{r include=FALSE}
devtools::install("../ndimclusteringR/")
library("ndimclusteringR")
```

## Iteration parameters

The parameters for the program are:

-   `dname` The directory where the data is saved.
    This should include the following files:

    -   `unstdBeta_df.csv` A `.csv` file with columns seperated by `,` and rows by `;` , each row corresponds to a snp and each column is a trait.
        The values correspond to the intensity of association determined from a GWAS.
        The data is sourced from openGWAS.

    -   `unstdSE_df.csv` A `.csv` file with columns seperated by `,` and rows by `;` , each row corresponds to a snp and each column is a trait.
        The values correspond to the standard error of the association determined from a GWAS.
        The data is sourced from openGWAS.

    -   `pval_df.csv` A `.csv` file with columns seperated by `,` and rows by `;` , each row corresponds to a snp and each column is a trait.
        The values correspond to the $p$-values of the association determined from a GWAS.
        The $p$-values are the probability that the intensity values are observed due to chance.
        The data is sourced from openGWAS.

    -   `trait_info_nfil.csv` A `.csv` file with columns seperated by `,` and rows by `;` , each row corresponds to a trait.
        The label for the trait is `phenotype`, to get the full definition for the trait as used in the data collection this is found in the column `description`.

-   `clust_type` method of clustering to be used.

-   `basic` is a standard $k$-means clustering method.

-   `min` is an iteration of $k$-means, which minimises the $aic$ from cluster sets run from $1$ cluster to $k$.

-   `dbscan` density based clustering method.

-   `pca_type` method for determining the principle components.
    See [PCA section](#pca)

    -   `prcomp` PCA is performed using the `prcomp` package.
    -   `none` no PCA is performed and the data is clustered without PCA.

-   `nclust` The number of clusters to search for when using `basic` or `min` clustering.

-   `n_pcs` The number of principal components to reduce to.
    This term is only used if `pca_type` is NOT `none`.

-   `bin_angles` Binary switch determining whether the data should be transformed to the angle space or not.
    If $0$ then nothing is done, if $1$ then the data is transformed from the intensity scores to the angle of those scores to the axis in that data-space.
    Since the angle describe a position betwen two axes by using the angles we can reduce the dimension of the data-space by $1$, if we wanted to retained all information we would also store the distance from the origin but we are searching for elements on the same line, it does not matter to our clusters where on the line they are, therefore we do not store this distance.

-   `bin_p_clust` Binary switch.
    If $0$ then $k$-means clustering calculated the cluster centroids based on the average of the terms in that cluster.
    If $1$ then the cluster centroids are recalculated based on a weighted average using the intensity and the $p$-values.
    See [$p$-value weighting section](#cluster_p_weight).

-   `bin_p_score` Binary switch indicating the weighting when scoring clusters on trait axis.
    If $0$ then the clusters are scored based on their elements average intensity scores on each axis.
    If $1$ then the clusters are scored based on a weight average of their elements scores on each trait, weighted by the $p$-value that the intensity score is a true representation.

-   `how_cents` The method to be used for initialising the centres of the clusters.

    -   `rand` The value on each axis is randomly assigned using a uniform distribution between the max and min on each axis.
    -   `points` The centre for each cluster is assigned to points from the dataset. The points are randomly selected with a uniform distribution.

### What happens within the program? - Algorithm: Step by step {#alg_steps}

If all the steps are included then they are performed in the following order.

1\.
Crop data to complete cases.

2\.
Convert data to angles.

3\.
Perform PCA on angle data.

4\.
Cluster on the PCA\
a) Set cluster centres

b)  Converge cluster centres

c)  if min then rerun for different number of clusters and choose set with min-aic.

### Test 1 {#test1}

Run the tests with:

-   No PCA

-   basic k-means clustering.
    k is set to the number of pathways.

-   no angles calculated before clustering.

-   number of pathways 2.

```{r include=FALSE}
data_dir <- "../TestData/paths"
pc_type <- "none"
clust_typ <- "basic"
bin_angles <- 0
num_paths <- 2
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
    dname = paste0(data_dir, num_paths, "/"),
    clust_type = clust_typ,
    pca_type = pc_type,
    nclust = nc,
    n_pcs = 3,
    bin_angles = bin_angles,
    bin_p_clust = bin_p_clust,
    bin_p_score = 1,
    how_cents = "rand"
  )
res_dir <- make_path_label_str(iter_traits)
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```

### Test 2 {#test2}

For test2 we will keep the parameters the same as [test1](#test1) but increase the number of pathways.

Run the tests with:

-   No PCA

-   basic k-means clustering.
    k is set to the number of pathways.

-   no angles calculated before clustering.

-   **number of pathways 4.**

-   Clusters centres are not weighted by the p-values.

```{r include=FALSE}
pc_type <- "none"
clust_typ <- "basic"
bin_angles <- 0
num_paths <- 4
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
    dname = paste0(data_dir, num_paths, "/"),
    clust_type = clust_typ,
    pca_type = pc_type,
    nclust = nc,
    n_pcs = 3,
    bin_angles = bin_angles,
    bin_p_clust = bin_p_clust,
    bin_p_score = 1,
    how_cents = "rand"
  )
res_dir <- make_path_label_str(iter_traits)
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```

## Calculating Angles {#angles}
The data-points for each snp have an intensity score associated with each trait. We want to identify lines within our data but we can see from the first two tests that standard clustering does not detect these lines. To try and convert data that is visualised as lines to something that looks like balls of data we convert the data to the angle to each axis.

1. Create a unit-vector for each axis (you can remove one axis since the angles reduce the dimension), the algorithm removes the last axis.
2. For each unit vector found and each data-point $x$:
  i) $$\theta = \frac{x \cdot u}{||u|| ||x||}$$
  ii) If $\theta > \pi$ reassign the angle $\theta= \theta-\pi$. These are angles on opposite sides of the circle but they lie on the same line so we want the algorithm to group them together.

### Test 3 {#test3}

For test3 we will return to the case of two pathways but this time we will reformat the data before clustering.
We will transform the data from the raw $\beta$ intensity scores to the angles of the scores when transformed to a polar-coordinate system.

Run the tests with:

-   No PCA

-   basic k-means clustering.
    k is set to the number of pathways.

-   **angles calculated.**

-   number of pathways 2.

```{r include=FALSE}
pc_type <- "none"
bin_angles <- 1
num_paths <- 4
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
    dname = paste0(data_dir, num_paths, "/"),
    clust_type = clust_typ,
    pca_type = pc_type,
    nclust = nc,
    n_pcs = 3,
    bin_angles = bin_angles,
    bin_p_clust = bin_p_clust,
    bin_p_score = 1,
    how_cents = "rand"
  )
res_dir <- make_path_label_str(iter_traits)
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```

### Test 4 {#test4}

For test4 we use the angles again but we investigate the case with 4 pathways.

Run the tests with:

-   No PCA

-   basic k-means clustering.
    k is set to the number of pathways.

-   angles calculated before clustering.

-   number of pathways 4.

```{r include=FALSE}
pc_type <- "none"
clust_typ <- "basic"
bin_angles <- 1
num_paths <- 4
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
    dname = paste0(data_dir, num_paths, "/"),
    clust_type = clust_typ,
    pca_type = pc_type,
    nclust = nc,
    n_pcs = 3,
    bin_angles = bin_angles,
    bin_p_clust = bin_p_clust,
    bin_p_score = 1,
    how_cents = "rand"
  )
res_dir <- make_path_label_str(iter_traits)
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```

## Consider the location of the centroids. {#how_cents}

The previous tests used centroids assigned randomly within the ranges on each axis.
The results show that although we ask for $k$ clusters we often get some of the clusters returning as empty.
This is likely to be caused by the initial centroids being outside the data-space.

Instead we will initialise the centroids using randomly selected points from out dataset.

### Test 5 {#test5}

For test5 we keep the parameters the same as [test2](#test2) but we change the initialisation of the cluster centroids.

Run the tests with:

-   No PCA

-   basic k-means clustering.
    k is set to the number of pathways.

-   no angles calculated before clustering.

-   number of pathways 4.

-   Centroids assigned using points

```{r include=FALSE}
pc_type <- "none"
clust_typ <- "basic"
how_cents <- "points"
bin_angles <- 0
num_paths <- 4
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
    dname = paste0(data_dir, num_paths, "/"),
    clust_type = clust_typ,
    pca_type = pc_type,
    nclust = nc,
    n_pcs = 3,
    bin_angles = bin_angles,
    bin_p_clust = bin_p_clust,
    bin_p_score = 1,
    how_cents = how_cents
  )
res_dir <- make_path_label_str(iter_traits)
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```

### Test 6 {#test6}

For test6 we keep the parameters the same as [test4](#test4) but we change the initialisation of the cluster centroids.

Run the tests with:

-   No PCA

-   basic k-means clustering.
    k is set to the number of pathways.

-   angles calculated before clustering.

-   number of pathways 4.

-   Centroids assigned using points

```{r include=FALSE}
pc_type <- "none"
clust_typ <- "basic"
how_cents <- "points"
bin_angles <- 1
num_paths <- 4
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
    dname = paste0(data_dir, num_paths, "/"),
    clust_type = clust_typ,
    pca_type = pc_type,
    nclust = nc,
    n_pcs = 3,
    bin_angles = bin_angles,
    bin_p_clust = bin_p_clust,
    bin_p_score = 1,
    how_cents = how_cents
  )
res_dir <- make_path_label_str(iter_traits)
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```

## Principal Components {#pca}

So far we have ignored the principal components option.
This is another method for reducing the dimension.
It identifies the eigen-vectors and corresponding eigen-values of the data space.
Then outputs the set of eigen-vectors with the largest eigen-values as a matrix.
This matrix is then used to transform the data onto a new data-space with reduced dimension.
The principal components characterise the variation in the data.
By defining the axes as the eigen-vectors we remove the highest levels of correlation within the data.
In doing this we are trying to find the level at which the data separates into distinct categories.

PCA steps:

1.  Ensure each data axis is normalised.
2.  Identify the eigen-vectors and eigen-values of the data-space.
3.  Use the eigen-vectors of the `n_pc` largest eigen-values to form the columns of a matrix.
4.  Take each data-point as a row-vector and multiply by the matrix to transform the data onto a new data-space.
5.  Transform the p-value matrix and standard error matrix onto the same dataspace.
6.  Store the transform matrix. This represents the proportion of each trait which makes up each pc vector.

[`prcomp`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp) is a pca package in R.

### Test 7 {#test7}

For the first pca test we will turn off the calculation of angles and use a standard k-means clustering to try and visualise what the pca is doing on it's own.
This is [test5](#test5) with `how_cents` changed.

Run the tests with:

-   PCA method prcomp

-   basic k-means clustering.
    k is set to the number of pathways.

-   no angles calculated before clustering.

-   number of pathways 4.

-   Centroids assigned using points

```{r include=FALSE}
pc_type <- "prcomp" 
clust_typ <- "basic"
how_cents <- "points"
bin_angles <- 0
num_paths <- 4
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
  dname = paste0(data_dir, num_paths, "/"),     
  clust_type = clust_typ,     
  pca_type = pc_type,     
  nclust = nc,     
  n_pcs = 3,     
  bin_angles = bin_angles,     
  bin_p_clust = bin_p_clust,     
  bin_p_score = 1,     
  how_cents = how_cents   ) 
res_dir <- make_path_label_str(iter_traits) 
iter_traits$res_dir <- res_dir 
clustering_program(iter_traits)
```

### Test 8 {#test8}

For the second pca test we will include the calculation of angles and use a standard k-means clustering to try and visualise what how the pca works with the angle data.
This is [test6](#test6) with `how_cents` changed.

Run the tests with:

-   PCA method prcomp

-   basic k-means clustering.
    k is set to the number of pathways.

-   angles calculated before clustering.

-   number of pathways 4.

-   Centroids assigned using points

```{r include=FALSE}
pc_type <- "prcomp"
clust_typ <- "basic"
how_cents <- "points"
bin_angles <- 1 
num_paths <- 4 
bin_p_clust <- 0
```

```{r echo=FALSE}
nc <- num_paths 
iter_traits <- list(   
  dname = paste0(data_dir, num_paths, "/"),        
  clust_type = clust_typ,        
  pca_type = pc_type,        
  nclust = nc,        
  n_pcs = 3,        
  bin_angles = bin_angles,        
  bin_p_clust = bin_p_clust,        
  bin_p_score = 1,        
  how_cents = how_cents   )  
res_dir <- make_path_label_str(iter_traits)  
iter_traits$res_dir <- res_dir  
clustering_program(iter_traits)
```

## Weight cluster centroid by p-value {#cluster_p_weight}

Each data-point has an associated p-value.
This corresponds to the chance the score observed is due to chance.
We do not want to skew our conclusions by unreliable snps.
Therefore when the cluster centroids are found we will use a weighted average based on the p-value.
For each co-ordinate in the cluster centroid the new centroid after cluster assignment is given by:

$$
\pmb{c}_i = \frac{\sum_{\text{points in cluster}}\beta_i(1-p_i)}{\sum_{\text{points in cluster}}(1-p_i)}
$$

### Test 9 {#test9}

Run the tests with:

-   PCA method prcomp

-   basic k-means clustering.
    k is set to the number of pathways.

-   angles calculated before clustering.

-   number of pathways 4.

-   Centroids assigned using points

-   Centroids reassigned during clustering using a p-value weighting.

```{r include=FALSE}
pc_type <- "prcomp"
clust_typ <- "basic"
how_cents <- "points"
bin_angles <- 1
num_paths <- 4
bin_p_clust <- 1
```

```{r echo=FALSE}
nc <- num_paths
iter_traits <- list(
  dname = paste0(data_dir, num_paths, "/"),
  clust_type = clust_typ,
  pca_type = pc_type,
  nclust = nc,
  n_pcs = 3,
  bin_angles = bin_angles,
  bin_p_clust = bin_p_clust,
  bin_p_score = 1,
  how_cents = how_cents   ) 
res_dir <- make_path_label_str(iter_traits) 
iter_traits$res_dir <- res_dir
clustering_program(iter_traits)
```
